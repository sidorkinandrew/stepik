# -*- coding: utf-8 -*-
"""4852-introToDSandML-3.5-all-steps.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sa-k34i7ubFGH3pBdWUOdhS93z4EZkyT
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

dataset_url = 'https://stepik.org/media/attachments/course/4852/training_mush.csv'
train = pd.read_csv(dataset_url)

train.head()

X, y = train.drop(['class'], axis=1), train['class']
X.shape, y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
                                X, y, test_size=0.33, random_state=0)

X.head()

rf = RandomForestClassifier(10, max_depth=5)

rf.fit(X_train, y_train)

predictions = rf.predict(X_test)

from sklearn.model_selection  import GridSearchCV

parametrs = {'n_estimators': range(10,51,10), 'max_depth': range(1,13,2),
             'min_samples_leaf': range(1,8), 'min_samples_split': range(2,10,2)}

grid_search_cv_rf = GridSearchCV(rf, parametrs, cv=3)
grid_search_cv_rf.fit(X_train, y_train)


best_clf = grid_search_cv_rf.best_estimator_
best_clf.score(X_test, y_test)

print(grid_search_cv_rf.best_params_)

feature_importances = best_clf.feature_importances_
feature_importances_df = pd.DataFrame({'features': list(X_train),
                                    'feature_importances': feature_importances})
feature_importances_df = feature_importances_df.sort_values('feature_importances', ascending=False)

print(feature_importances_df.head(5))

imp = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=['importance'])
imp.sort_values('importance').plot(kind='barh', figsize=(12, 8))

dataset_url = 'https://stepik.org/media/attachments/course/4852/testing_mush.csv'
test = pd.read_csv(dataset_url)

y_pred = best_clf.predict(test)
sum(y_pred)

# Cool!Move_forward!
# 'https://stepik.org/media/attachments/course/4852/testing_y_mush.csv.zip'

dataset_url = '/content/drive/My Drive/stepic/4852-introToDSandML/testing_y_mush.csv'
y_true = pd.read_csv(dataset_url)
y_true.head()

import seaborn as sns
from sklearn.metrics import confusion_matrix

sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, cmap="Blues")

# invasion data_set

dataset_url = 'https://stepik.org/media/attachments/course/4852/invasion.csv'
train = pd.read_csv(dataset_url)

dataset_url = 'https://stepik.org/media/attachments/course/4852/operative_information.csv'
test = pd.read_csv(dataset_url)

test.head()

X.head()

X, y = train.drop(['class'], axis=1), train['class']
X.shape, y.shape

rf = RandomForestClassifier(10, max_depth=5)

rf.fit(X, y)

from sklearn.model_selection  import GridSearchCV

parametrs = {'n_estimators': range(10,51,10), 'max_depth': range(1,13,2),
             'min_samples_leaf': range(1,8), 'min_samples_split': range(2,10,2)}

grid_search_cv_rf = GridSearchCV(rf, parametrs, cv=3)
grid_search_cv_rf.fit(X, y)

best_clf = grid_search_cv_rf.best_estimator_
best_clf.score(X, y)
grid_search_cv_rf.best_params_

y_pred = best_clf.predict(test)

pd.Series(y_pred).value_counts()

feature_importances = best_clf.feature_importances_
feature_importances_df = pd.DataFrame({'features': list(test),
                                    'feature_importances': feature_importances})
feature_importances_df = feature_importances_df.sort_values('feature_importances', ascending=False)

print(feature_importances_df.head(5))

# 

dataset_url = 'https://stepik.org/media/attachments/course/4852/space_can_be_a_dangerous_place.csv'
data = pd.read_csv(dataset_url)

data.head()

data.corr()

import matplotlib.pyplot as plt


plt.figure(figsize=(12,10))
sns.heatmap(data.drop(['peradventure_index'], axis=1).corr(), annot=True, cmap='viridis')
plt.show()

X, y = data.drop(['dangerous','peradventure_index'], axis=1), data['dangerous']
X.shape, y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

rf = RandomForestClassifier(10, max_depth=5)

rf.fit(X_train, y_train)

from sklearn.model_selection  import RandomizedSearchCV

parametrs = {'n_estimators': range(10,51,10), 'max_depth': range(1,13,2),
             'min_samples_leaf': range(1,8), 'min_samples_split': range(2,10,2)}

grid_search_cv_rf = RandomizedSearchCV(rf, parametrs, cv=3)
grid_search_cv_rf.fit(X_train, y_train)

best_clf = grid_search_cv_rf.best_estimator_
print(best_clf.score(X_test, y_test))
grid_search_cv_rf.best_params_

feature_importances = best_clf.feature_importances_
feature_importances_df = pd.DataFrame({'features': list(X_test),
                                    'feature_importances': feature_importances})
feature_importances_df = feature_importances_df.sort_values('feature_importances', ascending=False)

print(feature_importances_df.head(5))

